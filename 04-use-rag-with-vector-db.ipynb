{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. RAG med Vector Databas\n",
    "\n",
    "- mer avancerade uppslag av data som sedan skickas med i prompten\n",
    "\n",
    "![04 diagram](docs/04.drawio.png)\n",
    "\n",
    "- med en vector databas kan man söka på ostrukturerat data\n",
    "- en modell skapar 'vector embeddings' som lagras i databas\n",
    "- av frågan som ställs skapas också en 'vector embedding' av samma modell\n",
    "- nu kan man matematisk avgöra semantiska matchningar via 'nearest neighbour'-algoritm\n",
    "\n",
    "![01 vector](docs/vector01.png)\n",
    "\n",
    "![02 vector](docs/vector02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "import chromadb\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ladda filer in i vector databas\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"data/vector_db\")\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(name=\"spoe-data\")\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"data/documents\")\n",
    "raw_documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "documents = []\n",
    "metadata = []\n",
    "ids = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for chunk in chunks:\n",
    "    documents.append(chunk.page_content)\n",
    "    ids.append(\"ID\" + str(i))\n",
    "    metadata.append(chunk.metadata)\n",
    "    i += 1\n",
    "\n",
    "collection.upsert(documents=documents, metadatas=metadata, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definera prompt\n",
    "\n",
    "user_prompt = \"hur lång tid kommer genomförandet av SPOE-projektet att pågå?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ställ fråga (prompt) till vector db först\n",
    "\n",
    "results = collection.query(query_texts=[user_prompt], n_results=4)\n",
    "\n",
    "print(results[\"documents\"])\n",
    "print(results[\"metadatas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definera prompt för LLM, i denna ingår sökresultat från vector db\n",
    "\n",
    "system_prompt = (\n",
    "    \"\"\"\n",
    "You are a helpful assistant. You answer questions about the SPOE project. \n",
    "But you only answer based on knowledge I'm providing you. You don't use your internal \n",
    "knowledge and you don't make things up. If you don't know the answer, just say: I don't know\n",
    "--------------------\n",
    "The data:\n",
    "\"\"\"\n",
    "    + str(results[\"documents\"])\n",
    "    + \"\"\"\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "contents = []\n",
    "contents.append(types.Content(role=\"model\", parts=[types.Part(text=system_prompt)]))\n",
    "contents.append(types.Content(role=\"user\", parts=[types.Part(text=user_prompt)]))\n",
    "\n",
    "response = client.models.generate_content(model=\"gemini-2.0-flash\", contents=contents)\n",
    "\n",
    "print(response.candidates[0].content.parts[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
